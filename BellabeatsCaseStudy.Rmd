---
title: "Case Study: Bellabeats Data Analysis"
author: "Alfredo Ormeno"
date: "2023-04-11"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

------------------------------------------------------------------------

*The case study follows the six step data analysis process:*

### Ask

### Prepare

### Process

### Analyze

### Share

### Act

<br>

## Scenario

------------------------------------------------------------------------

Bellabeats is a tech-driven wellness company for women. Since the company's establishment in 2013, Bellbeats has grown rapidly and has the potential to become a larger player in the global smart device market. The company has 5 focus products: bellabeat app, leaf, time, spring and bellabeat membership. Our team has been asked to analyze smart device data to gain insight into how consumers are using their smart devices. The insights we discover will then help guide the marketing strategy for the company.

## 1. ASK

------------------------------------------------------------------------

**Bussiness Task:**

Analyze consumers use of an existing competitor smart device to identify potential opportunities for growth and recommendations for the Bellabeat marketing strategy

*Primary stakeholders:* Urška Sršen and Sando Mur, executive team members.

*Secondary stakeholders:* Bellabeat marketing analytics team.

**Questions for the analysis:**

1.  What are some trends in smart device usage?

2.  How could these trends apply to Bellabeat customers?

3.  How could these trends help influence Bellabeat's marketing strategy?

## 2. Prepare

---

Data Source: 30 participants FitBit Fitness Tracker Data from Mobius: <https://www.kaggle.com/arashnic/fitbit>

This dataset generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016-05.12.2016. Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring. Individual reports can be parsed by export session ID (column A) or timestamp (column B). Variation between output represents use of different types of Fitbit trackers and individual tracking behaviors / preferences.

This dataset contains 18 CSV files. The ROCCC approach was used to explore the credibility of this data.

-   Reliability: There is no information about the margin of error and a small sample size (30 participants) has been used, which can limit the amount of analysis that can be done.

-   Original: This data set is second hand data source. This data was collect by Amazon Mechanical Turk and not directly by the researcher.

-   Comprehensive: Data provides minute-level output for physical activity, heart rate, and sleep monitoring. While the data tracks many factors in the user activity and sleep, the sample size is small and most data is recorded during certain days of the week.

-   Current: Data is from March 2016 to May 2016. Data is not current so it may not reflect the latest trends in smart device usage among users.

-   Cited: Amazon Mechanical Murk created the dataset, but we have no information on whether this is a credible source.

This data set has limitations:

-   Only 30 user data is available. The central limit theorem general rule of n≥30 applies and we can use the t test for statstic reference. However, a larger sample size is preferred for the analysis.

-   Most data is recorded from Tuesday to Thursday, which may not be comprehensive enough to form an accurate analysis.

-   Ther is an absence of key characteristics of the participants, such as gender, age, location, lifestyle.

The goal is to analyze consumer data to help drive Bellabeats marketing strategy. This will require us to understand how consumers are using their smart devices in their daily lives. This means for the scope of our analysis, we want to focus on daily data logs where applicable. Hourly and minute data logs are too narrow for the purpose of our analysis. Therefore for this analysis the datasets for daily activity, daily calories, daily intensities, daily steps, heartrate by seconds, minute METs, daily sleep, and weight log information, will be used.

R Studio was used to complete this analysis because of the many packages and data visualization features available to explore the data with.

**Installing and loading of packages:**

```{r packages, message=FALSE, warning=FALSE}
install.packages("tidyverse")
install.packages("here")
install.packages("skimr")
install.packages("janitor")
install.packages("dplyr")

library("here")
library("skimr")
library("janitor")
library("dplyr")
library("tidyverse")
```

**Importing datasets:**

The csv files were first opened in Excel and the formatting for the time and/or date was changed from "custom" to "time" and/or "short date" where appropriate. The files were then imported into R Studio and the data frames were created with simplified names.

```{r import datasets}
# Import Datasets

# get file names from directory
setwd("/cloud/project")

files <- list.files(path = "./Fitabase Data 4.12.16-5.12.16")

# Split to save names; name for data frame will be first element
names <- strsplit(files, "\\.")

# now get the files

setwd("/cloud/project/Fitabase Data 4.12.16-5.12.16") # Change directory to dataset directory in order to open and read files 

for (i in 1:length(files)) { # for each file in the list named files
    
  fileName <- files[i] # save file name of element i
  
  dataName <- names[[i]][[1]] # save data name of element i
  print(dataName)

  tempData <- read.csv(fileName) # read csv file
  
  assign (dataName, tempData, envir=.GlobalEnv) # assign the results of the file to teh data named
}

setwd(here()) # Change back to root directory
```

## 3. Process

---

**Viewing the Data Frames**
To ensure the data frames were imported correctly, the `head()` function is used. The `colnames()` and `glimpse()` functions were used to explore the data frames and find null values, and find commonalitites. Any commonalities represent an opportunity to remove unnecessary duplicate data frames. 

*dailyActivity:*

```{r dailyActivity DF}

head(dailyActivity_merged)

colnames(dailyActivity_merged)

glimpse(dailyActivity_merged)
```

*dailyCalories:*

```{r dailyCalories DF}
head(dailyCalories_merged)

colnames(dailyCalories_merged)

glimpse(dailyCalories_merged)
```

*dailyIntensities:*
```{r dailyIntensities DF}
head(dailyIntensities_merged)

colnames(dailyIntensities_merged)

glimpse(dailyIntensities_merged)
```

*dailySteps:*
```{r dailySteps DF}
head(dailySteps_merged)

colnames(dailySteps_merged)

glimpse(dailySteps_merged)

# heartrate_seconds
head(heartrate_seconds_merged)

colnames(heartrate_seconds_merged)

glimpse(heartrate_seconds_merged)
```

*minuteMets:*
```{r minuteMets DF}
head(minuteMETsNarrow_merged)

colnames(minuteMETsNarrow_merged)

glimpse(minuteMETsNarrow_merged)
```

*sleepDay:*
```{r sleepDay DF}
head(sleepDay_merged)

colnames(sleepDay_merged)

glimpse(sleepDay_merged)
```

*weightLogs:*
```{r weightLogs DF}
head(weightLogInfo_merged)

colnames(weightLogInfo_merged)

glimpse(weightLogInfo_merged)
```

**Removing data frames:**
All eight of the data frames contain the “Id” column, so all dataframes can be merged. It is important to note that the daily_activity data frame appears to contain data for calories, intensities, and steps, thus all other daily data frames possibly contain duplicate data and can be removed. In order to use the daily_activity frame in place of daily_calories, daily_intensities, and daily_steps, the number of observations must be the same and the observations must match for each ID number.

The sqldf package is loaded to utilize SQL syntax to determine if the values in the dailyCalories, dailyIntensitites, and dailySteps are present within the dailyActivity data frame. The number of columns must be the same between the data frames so a temporary dat frame witht the important columns is created first. 
